{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ba458e",
   "metadata": {},
   "source": [
    "# Import Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6bed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2ee5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6afd73",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846579a",
   "metadata": {},
   "source": [
    "### Hyperparameter (Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d112fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGS = {\n",
    "    \"hsv_h\": 0.015,  # (float) image HSV-Hue augmentation (fraction)\n",
    "    \"hsv_s\": 0.7,  # (float) image HSV-Saturation augmentation (fraction)\n",
    "    \"hsv_v\": 0.4,  # (float) image HSV-Value augmentation (fraction)\n",
    "    \"degrees\": 0.1,  # (float) image rotation (+/- deg)\n",
    "    \"translate\": 0.1,  # (float) image translation (+/- fraction)\n",
    "    \"scale\": 0.5,  # (float) image scale (+/- gain)\n",
    "    \"shear\": 0.1,  # (float) image shear (+/- deg)\n",
    "    \"perspective\": 0.0001,  # (float) image perspective (+/- fraction), range 0-0.001\n",
    "    \"flipud\": 0.1,  # (float) image flip up-down (probability)\n",
    "    \"fliplr\": 0.5,  # (float) image flip left-right (probability)\n",
    "    \"mosaic\": 0.8,  # (float) image mosaic (probability)\n",
    "    \"mixup\": 0.4,  # (float) image mixup (probability)\n",
    "    \"copy_paste\": 0.0  # (float) segment copy-paste (probability)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c7af5",
   "metadata": {},
   "source": [
    "### Fine Tuning Model with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be911b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data='D:\\\\Pemrograman\\\\Data Science\\\\Gemastik\\\\DatasetV2\\\\data.yaml', epochs=250, imgsz=640,**ARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b760127",
   "metadata": {},
   "source": [
    "### Continue Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"D:\\\\Pemrograman\\\\Data Science\\\\Gemastik\\\\runs\\\\detect\\\\train4\\\\weights\\\\last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00283e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(resume=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358b68e",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7038ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"D:\\\\Pemrograman\\\\Data Science\\\\Gemastik\\\\runs\\\\detect\\\\train4\\\\weights\\\\best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3ea0fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malif\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.7 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Pemrograman\\Data Science\\Gemastik\\DatasetV2\\test\\labels.cache... 1066 images, 43 backgrounds, 0 corrup\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 67/67 [00:10\n",
      "                   all       1066       2200      0.951      0.968      0.971      0.733\n",
      "Speed: 0.3ms preprocess, 3.1ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val26\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x000002A7A5B8E410>\n",
       "fitness: 0.7565601843453638\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.73277])\n",
       "names: {0: 'face_mask'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9508928571428571, 'metrics/recall(B)': 0.9681818181818181, 'metrics/mAP50(B)': 0.970646606884178, 'metrics/mAP50-95(B)': 0.7327728040632733, 'fitness': 0.7565601843453638}\n",
       "save_dir: WindowsPath('runs/detect/val26')\n",
       "speed: {'preprocess': 0.2680914039683387, 'inference': 3.1119101937671543, 'loss': 0.0028151732224684497, 'postprocess': 0.7929294239065661}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val(conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce35e5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.131  Python-3.10.7 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Pemrograman\\Data Science\\Gemastik\\DatasetV2\\test\\labels.cache... 1066 images, 43 backgrounds, 0 corrup\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 67/67 [00:11\n",
      "                   all       1066       2200       0.96      0.961      0.979      0.706\n",
      "Speed: 0.3ms preprocess, 3.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val27\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x000002A93FB2F190>\n",
       "fitness: 0.7336223179212259\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.7063])\n",
       "names: {0: 'face_mask'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9600529168123482, 'metrics/recall(B)': 0.9613246889163309, 'metrics/mAP50(B)': 0.9794974706432505, 'metrics/mAP50-95(B)': 0.7063028565076677, 'fitness': 0.7336223179212259}\n",
       "save_dir: WindowsPath('runs/detect/val27')\n",
       "speed: {'preprocess': 0.27144939322408995, 'inference': 3.1124715733483406, 'loss': 0.0011668196314942323, 'postprocess': 0.9527474809542829}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a818950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.131  Python-3.10.7 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Pemrograman\\Data Science\\Gemastik\\DatasetV2\\test\\labels.cache... 1066 images, 43 backgrounds, 0 corrup\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 67/67 [00:11\n",
      "                   all       1066       2200       0.96      0.961      0.974      0.734\n",
      "Speed: 0.3ms preprocess, 3.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val28\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x000002A93FB0AE60>\n",
       "fitness: 0.758275052593317\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.73431])\n",
       "names: {0: 'face_mask'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9600529168123482, 'metrics/recall(B)': 0.9613246889163309, 'metrics/mAP50(B)': 0.9739536768439294, 'metrics/mAP50-95(B)': 0.7343107610099155, 'fitness': 0.758275052593317}\n",
       "save_dir: WindowsPath('runs/detect/val28')\n",
       "speed: {'preprocess': 0.2683750013025796, 'inference': 3.051626749378655, 'loss': 0.002094997026683242, 'postprocess': 0.9208213097606323}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val(conf=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa505477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malif\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.7 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Pemrograman\\Data Science\\Gemastik\\DatasetV2\\test\\labels.cache... 1066 images, 43 backgrounds, 0 corrup\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 67/67 [00:10\n",
      "                   all       1066       2200       0.96      0.961      0.976      0.734\n",
      "Speed: 0.3ms preprocess, 3.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val30\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x000001A88EFDA9E0>\n",
       "fitness: 0.7584757201835935\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.73429])\n",
       "names: {0: 'face_mask'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9600529168123482, 'metrics/recall(B)': 0.9613246889163309, 'metrics/mAP50(B)': 0.9761505429673918, 'metrics/mAP50-95(B)': 0.7342896287631715, 'fitness': 0.7584757201835935}\n",
       "save_dir: WindowsPath('runs/detect/val30')\n",
       "speed: {'preprocess': 0.2596416348140638, 'inference': 3.048805984726095, 'loss': 0.0, 'postprocess': 0.8114527135136874}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val(conf=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97cd8e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.131  Python-3.10.7 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Pemrograman\\Data Science\\Gemastik\\DatasetV2\\test\\labels.cache... 1066 images, 43 backgrounds, 0 corrup\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 67/67 [00:11\n",
      "                   all       1066       2200       0.96      0.961      0.979      0.735\n",
      "Speed: 0.3ms preprocess, 3.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val31\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x000001A9C9CA43D0>\n",
       "fitness: 0.7598096277591048\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.7354])\n",
       "names: {0: 'face_mask'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9600529168123482, 'metrics/recall(B)': 0.9613246889163309, 'metrics/mAP50(B)': 0.9794974706432505, 'metrics/mAP50-95(B)': 0.7353998674386442, 'fitness': 0.7598096277591048}\n",
       "save_dir: WindowsPath('runs/detect/val31')\n",
       "speed: {'preprocess': 0.2760594155059299, 'inference': 2.984631575965523, 'loss': 0.0, 'postprocess': 0.9393273777630718}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val(conf=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6923f2e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.131  Python-3.10.7 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Pemrograman\\Data Science\\Gemastik\\DatasetV2\\test\\labels.cache... 1066 images, 43 backgrounds, 0 corrup\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 67/67 [00:11\n",
      "                   all       1066       2200       0.96      0.961      0.979      0.735\n",
      "Speed: 0.3ms preprocess, 3.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val32\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x000001A9C9CA46D0>\n",
       "fitness: 0.7590209411893427\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.73452])\n",
       "names: {0: 'face_mask'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9600529168123482, 'metrics/recall(B)': 0.9613246889163309, 'metrics/mAP50(B)': 0.9794974706432505, 'metrics/mAP50-95(B)': 0.7345235490277974, 'fitness': 0.7590209411893427}\n",
       "save_dir: WindowsPath('runs/detect/val32')\n",
       "speed: {'preprocess': 0.27811929835163857, 'inference': 3.0431342616984813, 'loss': 0.0, 'postprocess': 0.8789833222723813}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val(conf=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddee37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malif\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.7 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Pemrograman\\Data Science\\Gemastik\\DatasetV2\\test\\labels.cache... 1066 images, 43 backgrounds, 0 corrup\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 67/67 [00:10\n",
      "                   all       1066       2200       0.96      0.961      0.978      0.735\n",
      "Speed: 0.3ms preprocess, 3.1ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val34\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x000001B4ACD65150>\n",
       "fitness: 0.7591697961136183\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.7349])\n",
       "names: {0: 'face_mask'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9600529168123482, 'metrics/recall(B)': 0.9613246889163309, 'metrics/mAP50(B)': 0.9775865422775004, 'metrics/mAP50-95(B)': 0.7349012687620758, 'fitness': 0.7591697961136183}\n",
       "save_dir: WindowsPath('runs/detect/val34')\n",
       "speed: {'preprocess': 0.2612528613092304, 'inference': 3.057299367035084, 'loss': 0.0009384656265573699, 'postprocess': 0.8363292096479749}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val(conf=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66323c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malif\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Ultralytics YOLOv8.0.131  Python-3.10.7 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Pemrograman\\Data Science\\Gemastik\\DatasetV2\\test\\labels.cache... 1066 images, 43 backgrounds, 0 corrup\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 67/67 [00:10\n",
      "                   all       1066       2200      0.969       0.94      0.958      0.727\n",
      "Speed: 0.3ms preprocess, 3.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val35\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x000002464B3A80D0>\n",
       "fitness: 0.7499241575518341\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.72682])\n",
       "names: {0: 'face_mask'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9686329588014981, 'metrics/recall(B)': 0.9404545454545454, 'metrics/mAP50(B)': 0.9578616964583263, 'metrics/mAP50-95(B)': 0.7268199865622238, 'fitness': 0.7499241575518341}\n",
       "save_dir: WindowsPath('runs/detect/val35')\n",
       "speed: {'preprocess': 0.27384051238841906, 'inference': 3.1612080436262806, 'loss': 8.610802340910091e-05, 'postprocess': 0.7673338698625117}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val(conf=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4b0fae",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c94e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file\n",
    "video_path = \"C:\\\\Users\\\\malif\\\\Downloads\\\\Dataset Tambahan\\\\drive-download-20230705T021720Z-001\\\\VID_20230704_155629.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        #resize frame\n",
    "        resize = cv2.resize(frame, (800, 600))\n",
    "        resize = cv2.flip(resize, 0)\n",
    "        \n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(resize)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
